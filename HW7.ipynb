{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустить seq2seq, seq2seq с внимаием и трансформер для перевода русских слов + описать наблюдения по качеству"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 35\n",
    "latent_dim = 256\n",
    "num_samples = 10000\n",
    "data_path = 'rus.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/35\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 1.1457 - accuracy: 0.7719 - val_loss: 0.9314 - val_accuracy: 0.7575\n",
      "Epoch 2/35\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 0.7504 - accuracy: 0.7987 - val_loss: 0.7888 - val_accuracy: 0.7951\n",
      "Epoch 3/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.6428 - accuracy: 0.8304 - val_loss: 0.6989 - val_accuracy: 0.8090\n",
      "Epoch 4/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.5737 - accuracy: 0.8428 - val_loss: 0.6437 - val_accuracy: 0.8201\n",
      "Epoch 5/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.5521 - accuracy: 0.8464 - val_loss: 0.6120 - val_accuracy: 0.8253\n",
      "Epoch 6/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.5133 - accuracy: 0.8539 - val_loss: 0.5874 - val_accuracy: 0.8295\n",
      "Epoch 7/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.4931 - accuracy: 0.8590 - val_loss: 0.5667 - val_accuracy: 0.8384\n",
      "Epoch 8/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.4754 - accuracy: 0.8631 - val_loss: 0.5494 - val_accuracy: 0.8407\n",
      "Epoch 9/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.4610 - accuracy: 0.8665 - val_loss: 0.5374 - val_accuracy: 0.8440\n",
      "Epoch 10/35\n",
      "8000/8000 [==============================] - 28s 4ms/step - loss: 0.4467 - accuracy: 0.8703 - val_loss: 0.5235 - val_accuracy: 0.8473\n",
      "Epoch 11/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.4336 - accuracy: 0.8739 - val_loss: 0.5156 - val_accuracy: 0.8496\n",
      "Epoch 12/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.4216 - accuracy: 0.8773 - val_loss: 0.5026 - val_accuracy: 0.8553\n",
      "Epoch 13/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.4099 - accuracy: 0.8810 - val_loss: 0.4952 - val_accuracy: 0.8572\n",
      "Epoch 14/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.3996 - accuracy: 0.8835 - val_loss: 0.4909 - val_accuracy: 0.8594\n",
      "Epoch 15/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.3905 - accuracy: 0.8863 - val_loss: 0.4821 - val_accuracy: 0.8609\n",
      "Epoch 16/35\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 0.3806 - accuracy: 0.8891 - val_loss: 0.4755 - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.3713 - accuracy: 0.8921 - val_loss: 0.4719 - val_accuracy: 0.8643\n",
      "Epoch 18/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.3621 - accuracy: 0.8945 - val_loss: 0.4669 - val_accuracy: 0.8651\n",
      "Epoch 19/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.3529 - accuracy: 0.8971 - val_loss: 0.4651 - val_accuracy: 0.8668\n",
      "Epoch 20/35\n",
      "8000/8000 [==============================] - 28s 4ms/step - loss: 0.3451 - accuracy: 0.8991 - val_loss: 0.4607 - val_accuracy: 0.8682\n",
      "Epoch 21/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.3359 - accuracy: 0.9021 - val_loss: 0.4551 - val_accuracy: 0.8702\n",
      "Epoch 22/35\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.3278 - accuracy: 0.9043 - val_loss: 0.4517 - val_accuracy: 0.8718\n",
      "Epoch 23/35\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 0.3197 - accuracy: 0.9062 - val_loss: 0.4502 - val_accuracy: 0.8719\n",
      "Epoch 24/35\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3112 - accuracy: 0.9088 - val_loss: 0.4481 - val_accuracy: 0.8724\n",
      "Epoch 25/35\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.3033 - accuracy: 0.9110 - val_loss: 0.4439 - val_accuracy: 0.8740\n",
      "Epoch 26/35\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.2955 - accuracy: 0.9135 - val_loss: 0.4416 - val_accuracy: 0.8754\n",
      "Epoch 27/35\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.2876 - accuracy: 0.9157 - val_loss: 0.4400 - val_accuracy: 0.8763\n",
      "Epoch 28/35\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.2804 - accuracy: 0.9176 - val_loss: 0.4390 - val_accuracy: 0.8765\n",
      "Epoch 29/35\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.2723 - accuracy: 0.9199 - val_loss: 0.4431 - val_accuracy: 0.8759\n",
      "Epoch 30/35\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.2656 - accuracy: 0.9218 - val_loss: 0.4416 - val_accuracy: 0.8757\n",
      "Epoch 31/35\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.2574 - accuracy: 0.9244 - val_loss: 0.4421 - val_accuracy: 0.8771\n",
      "Epoch 32/35\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 0.2501 - accuracy: 0.9263 - val_loss: 0.4391 - val_accuracy: 0.8782\n",
      "Epoch 33/35\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.2428 - accuracy: 0.9283 - val_loss: 0.4372 - val_accuracy: 0.8791\n",
      "Epoch 34/35\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.2356 - accuracy: 0.9306 - val_loss: 0.4404 - val_accuracy: 0.8794\n",
      "Epoch 35/35\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.2289 - accuracy: 0.9323 - val_loss: 0.4401 - val_accuracy: 0.8794\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите.\n",
      "\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите.\n",
      "\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здоравей.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здоравей.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здоравей.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здоравей.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здоравей.\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Бегите!\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Бегите!\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: Бегите!\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: Бегите!\n",
      "\n",
      "-\n",
      "Input sentence: Who?\n",
      "Decoded sentence: Кто?\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Вот о!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Вот о!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Вот о!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Вот о!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Вот о!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Вот о!\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Поега!\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Поега!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помогите!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помогите!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помогите!\n",
      "\n",
      "-\n",
      "Input sentence: Jump!\n",
      "Decoded sentence: Прыгай!\n",
      "\n",
      "-\n",
      "Input sentence: Jump!\n",
      "Decoded sentence: Прыгай!\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Прыгай!\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Прыгай!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Остановитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Остановитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Остановитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Ждите!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Ждите!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Ждите!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Ждите!\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Ждите.\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Ждите.\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Ждите.\n",
      "\n",
      "-\n",
      "Input sentence: Do it.\n",
      "Decoded sentence: Войта это.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Давай!\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Давай!\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Привет!\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Привет!\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Привет!\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Привет!\n",
      "\n",
      "-\n",
      "Input sentence: Hurry!\n",
      "Decoded sentence: Вытере!\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я была разока.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я была разока.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я была разока.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я была разока.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Я подлаю.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Я подлаю.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Я подлаю.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я потерялся.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я потерялся.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я потерялся.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я была на пистоко.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я была на пистоко.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я была на пистоко.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я была на пистоко.\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: Оненя сом!\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Расслабьтесь.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Расслабьтесь.\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Расслабьтесь.\n",
      "\n",
      "-\n",
      "Input sentence: Shoot!\n",
      "Decoded sentence: Стреся!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбойтесь!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбойтесь!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбойтесь!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбойтесь!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбойтесь!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбойтесь!\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Поела!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Вы вобрашее!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Вы вобрашее!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Вы вобрашее!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Вы вобрашее!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Вы вобрашее!\n",
      "\n",
      "-\n",
      "Input sentence: Eat it.\n",
      "Decoded sentence: Ждите сере.\n",
      "\n",
      "-\n",
      "Input sentence: Eat up.\n",
      "Decoded sentence: Веди.\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Застравьте это!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Застравьте это!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Застравьте это!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Застравьте это!\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Убидайся.\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Убидайся.\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Убидайся.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Понял!\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Покла!\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Покла!\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Покла!\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Покла!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq2seq с вниманием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(preprocess_sentence(input_text))\n",
    "    target_texts.append(preprocess_sentence(target_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
    "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.lstm(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n",
    "    \n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.lstm(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 1 Loss 0.1009\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 2 Loss 0.0296\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 3 Loss 0.0246\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 4 Loss 0.0213\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 5 Loss 0.0215\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 6 Loss 0.0211\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 7 Loss 0.0173\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 8 Loss 0.0175\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 9 Loss 0.0186\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 10 Loss 0.0164\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 11 Loss 0.0148\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 12 Loss 0.0140\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 13 Loss 0.0141\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 14 Loss 0.0131\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 15 Loss 0.0128\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 16 Loss 0.0129\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 17 Loss 0.0119\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 18 Loss 0.0126\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 19 Loss 0.0120\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 20 Loss 0.0111\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 21 Loss 0.0108\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 22 Loss 0.0099\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 23 Loss 0.0111\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 24 Loss 0.0102\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 25 Loss 0.0096\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 26 Loss 0.0092\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 27 Loss 0.0091\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 28 Loss 0.0109\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 29 Loss 0.0118\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 30 Loss 0.0118\n",
      "Step 0\n",
      "Step 25\n",
      "Step 50\n",
      "Step 75\n",
      "Step 100\n",
      "Epoch 31 Loss 0.0093\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 31\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        if not batch % 25: \n",
    "            print(f'Step {batch}')\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 14}\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "    \n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Prog\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['char', 'f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> good morning <end>\n",
      "Predicted translation: ! <end> \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ticker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-c62fe7b3b252>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pylab'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'good morning'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-61331b77bd12>\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted translation: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mattention_plot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_plot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mplot_attention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_plot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-61331b77bd12>\u001b[0m in \u001b[0;36mplot_attention\u001b[1;34m(attention, sentence, predicted_sentence)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_yticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpredicted_sentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultipleLocator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultipleLocator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ticker' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "translate(u'good morning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "трансформер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights\n",
    "    \n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = len(inp_lang_tokenizer.index_word) + 2\n",
    "target_vocab_size = len(targ_lang_tokenizer.index_word) + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "  \n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "  \n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.2036 Accuracy 0.1211\n",
      "Epoch 1 Batch 50 Loss 1.4319 Accuracy 0.2162\n",
      "Epoch 1 Batch 100 Loss 1.1832 Accuracy 0.2700\n",
      "Epoch 1 Loss 1.0453 Accuracy 0.3033\n",
      "Epoch 2 Batch 0 Loss 0.4681 Accuracy 0.4453\n",
      "Epoch 2 Batch 50 Loss 0.2283 Accuracy 0.4770\n",
      "Epoch 2 Batch 100 Loss 0.1903 Accuracy 0.4826\n",
      "Epoch 2 Loss 0.1750 Accuracy 0.4846\n",
      "Epoch 3 Batch 0 Loss 0.1019 Accuracy 0.4883\n",
      "Epoch 3 Batch 50 Loss 0.1210 Accuracy 0.4917\n",
      "Epoch 3 Batch 100 Loss 0.1162 Accuracy 0.4920\n",
      "Epoch 3 Loss 0.1173 Accuracy 0.4918\n",
      "Epoch 4 Batch 0 Loss 0.0519 Accuracy 0.4961\n",
      "Epoch 4 Batch 50 Loss 0.1022 Accuracy 0.4919\n",
      "Epoch 4 Batch 100 Loss 0.1005 Accuracy 0.4922\n",
      "Epoch 4 Loss 0.0961 Accuracy 0.4923\n",
      "Epoch 5 Batch 0 Loss 0.0820 Accuracy 0.4922\n",
      "Epoch 5 Batch 50 Loss 0.0908 Accuracy 0.4920\n",
      "Epoch 5 Batch 100 Loss 0.0813 Accuracy 0.4926\n",
      "Epoch 5 Loss 0.0834 Accuracy 0.4929\n",
      "Epoch 6 Batch 0 Loss 0.0105 Accuracy 0.5000\n",
      "Epoch 6 Batch 50 Loss 0.0808 Accuracy 0.4934\n",
      "Epoch 6 Batch 100 Loss 0.0723 Accuracy 0.4949\n",
      "Epoch 6 Loss 0.0731 Accuracy 0.4949\n",
      "Epoch 7 Batch 0 Loss 0.0640 Accuracy 0.4844\n",
      "Epoch 7 Batch 50 Loss 0.0661 Accuracy 0.4946\n",
      "Epoch 7 Batch 100 Loss 0.0659 Accuracy 0.4956\n",
      "Epoch 7 Loss 0.0677 Accuracy 0.4952\n",
      "Epoch 8 Batch 0 Loss 0.0309 Accuracy 0.4961\n",
      "Epoch 8 Batch 50 Loss 0.0585 Accuracy 0.4968\n",
      "Epoch 8 Batch 100 Loss 0.0615 Accuracy 0.4961\n",
      "Epoch 8 Loss 0.0636 Accuracy 0.4961\n",
      "Epoch 9 Batch 0 Loss 0.0143 Accuracy 0.5000\n",
      "Epoch 9 Batch 50 Loss 0.0579 Accuracy 0.4954\n",
      "Epoch 9 Batch 100 Loss 0.0597 Accuracy 0.4955\n",
      "Epoch 9 Loss 0.0600 Accuracy 0.4957\n",
      "Epoch 10 Batch 0 Loss 0.0837 Accuracy 0.4961\n",
      "Epoch 10 Batch 50 Loss 0.0597 Accuracy 0.4972\n",
      "Epoch 10 Batch 100 Loss 0.0625 Accuracy 0.4964\n",
      "Epoch 10 Loss 0.0608 Accuracy 0.4963\n",
      "Epoch 11 Batch 0 Loss 0.0262 Accuracy 0.5000\n",
      "Epoch 11 Batch 50 Loss 0.0547 Accuracy 0.4966\n",
      "Epoch 11 Batch 100 Loss 0.0528 Accuracy 0.4970\n",
      "Epoch 11 Loss 0.0540 Accuracy 0.4967\n",
      "Epoch 12 Batch 0 Loss 0.0290 Accuracy 0.5000\n",
      "Epoch 12 Batch 50 Loss 0.0477 Accuracy 0.4982\n",
      "Epoch 12 Batch 100 Loss 0.0518 Accuracy 0.4971\n",
      "Epoch 12 Loss 0.0519 Accuracy 0.4968\n",
      "Epoch 13 Batch 0 Loss 0.0302 Accuracy 0.4961\n",
      "Epoch 13 Batch 50 Loss 0.0630 Accuracy 0.4968\n",
      "Epoch 13 Batch 100 Loss 0.0603 Accuracy 0.4966\n",
      "Epoch 13 Loss 0.0569 Accuracy 0.4968\n",
      "Epoch 14 Batch 0 Loss 0.0998 Accuracy 0.4961\n",
      "Epoch 14 Batch 50 Loss 0.0521 Accuracy 0.4981\n",
      "Epoch 14 Batch 100 Loss 0.0525 Accuracy 0.4976\n",
      "Epoch 14 Loss 0.0526 Accuracy 0.4972\n",
      "Epoch 15 Batch 0 Loss 0.0461 Accuracy 0.5039\n",
      "Epoch 15 Batch 50 Loss 0.0474 Accuracy 0.4985\n",
      "Epoch 15 Batch 100 Loss 0.0475 Accuracy 0.4979\n",
      "Epoch 15 Loss 0.0512 Accuracy 0.4974\n",
      "Epoch 16 Batch 0 Loss 0.0721 Accuracy 0.4961\n",
      "Epoch 16 Batch 50 Loss 0.0492 Accuracy 0.4985\n",
      "Epoch 16 Batch 100 Loss 0.0470 Accuracy 0.4978\n",
      "Epoch 16 Loss 0.0500 Accuracy 0.4975\n",
      "Epoch 17 Batch 0 Loss 0.0203 Accuracy 0.5039\n",
      "Epoch 17 Batch 50 Loss 0.0483 Accuracy 0.4972\n",
      "Epoch 17 Batch 100 Loss 0.0533 Accuracy 0.4974\n",
      "Epoch 17 Loss 0.0528 Accuracy 0.4971\n",
      "Epoch 18 Batch 0 Loss 0.0091 Accuracy 0.5000\n",
      "Epoch 18 Batch 50 Loss 0.0478 Accuracy 0.4977\n",
      "Epoch 18 Batch 100 Loss 0.0486 Accuracy 0.4975\n",
      "Epoch 18 Loss 0.0505 Accuracy 0.4971\n",
      "Epoch 19 Batch 0 Loss 0.0438 Accuracy 0.5000\n",
      "Epoch 19 Batch 50 Loss 0.0424 Accuracy 0.4983\n",
      "Epoch 19 Batch 100 Loss 0.0480 Accuracy 0.4969\n",
      "Epoch 19 Loss 0.0537 Accuracy 0.4968\n",
      "Epoch 20 Batch 0 Loss 0.0198 Accuracy 0.4961\n",
      "Epoch 20 Batch 50 Loss 0.0356 Accuracy 0.4993\n",
      "Epoch 20 Batch 100 Loss 0.0481 Accuracy 0.4980\n",
      "Epoch 20 Loss 0.0480 Accuracy 0.4979\n",
      "Epoch 21 Batch 0 Loss 0.0190 Accuracy 0.5000\n",
      "Epoch 21 Batch 50 Loss 0.0424 Accuracy 0.4988\n",
      "Epoch 21 Batch 100 Loss 0.0463 Accuracy 0.4980\n",
      "Epoch 21 Loss 0.0471 Accuracy 0.4981\n",
      "Epoch 22 Batch 0 Loss 0.0932 Accuracy 0.4961\n",
      "Epoch 22 Batch 50 Loss 0.0443 Accuracy 0.4980\n",
      "Epoch 22 Batch 100 Loss 0.0450 Accuracy 0.4973\n",
      "Epoch 22 Loss 0.0465 Accuracy 0.4973\n",
      "Epoch 23 Batch 0 Loss 0.0128 Accuracy 0.5000\n",
      "Epoch 23 Batch 50 Loss 0.0490 Accuracy 0.4976\n",
      "Epoch 23 Batch 100 Loss 0.0471 Accuracy 0.4981\n",
      "Epoch 23 Loss 0.0499 Accuracy 0.4978\n",
      "Epoch 24 Batch 0 Loss 0.0439 Accuracy 0.4883\n",
      "Epoch 24 Batch 50 Loss 0.1172 Accuracy 0.4927\n",
      "Epoch 24 Batch 100 Loss 0.0817 Accuracy 0.4954\n",
      "Epoch 24 Loss 0.0749 Accuracy 0.4957\n",
      "Epoch 25 Batch 0 Loss 0.0547 Accuracy 0.4961\n",
      "Epoch 25 Batch 50 Loss 0.0464 Accuracy 0.4978\n",
      "Epoch 25 Batch 100 Loss 0.0448 Accuracy 0.4981\n",
      "Epoch 25 Loss 0.0467 Accuracy 0.4984\n",
      "Epoch 26 Batch 0 Loss 0.0588 Accuracy 0.5000\n",
      "Epoch 26 Batch 50 Loss 0.0416 Accuracy 0.4982\n",
      "Epoch 26 Batch 100 Loss 0.0483 Accuracy 0.4980\n",
      "Epoch 26 Loss 0.0479 Accuracy 0.4983\n",
      "Epoch 27 Batch 0 Loss 0.1231 Accuracy 0.4922\n",
      "Epoch 27 Batch 50 Loss 0.0665 Accuracy 0.4948\n",
      "Epoch 27 Batch 100 Loss 0.0663 Accuracy 0.4943\n",
      "Epoch 27 Loss 0.0733 Accuracy 0.4935\n",
      "Epoch 28 Batch 0 Loss 0.0234 Accuracy 0.5000\n",
      "Epoch 28 Batch 50 Loss 0.0683 Accuracy 0.4962\n",
      "Epoch 28 Batch 100 Loss 0.0619 Accuracy 0.4961\n",
      "Epoch 28 Loss 0.0622 Accuracy 0.4961\n",
      "Epoch 29 Batch 0 Loss 0.0439 Accuracy 0.5000\n",
      "Epoch 29 Batch 50 Loss 0.0529 Accuracy 0.4952\n",
      "Epoch 29 Batch 100 Loss 0.0533 Accuracy 0.4965\n",
      "Epoch 29 Loss 0.0541 Accuracy 0.4968\n",
      "Epoch 30 Batch 0 Loss 0.4786 Accuracy 0.4727\n",
      "Epoch 30 Batch 50 Loss 0.1002 Accuracy 0.4927\n",
      "Epoch 30 Batch 100 Loss 0.1908 Accuracy 0.4795\n",
      "Epoch 30 Loss 0.2938 Accuracy 0.4408\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "for epoch in range(30):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        train_step(inp, tar)\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [1]\n",
    "    end_token = [2]\n",
    "  \n",
    "    sentence = preprocess_sentence(inp_sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    \n",
    "    encoder_input = tf.expand_dims(inputs, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "    decoder_input = [1]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(max_length_targ):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == targ_lang_tokenizer.word_index[\"<end>\"]:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: good morning.\n",
      "Predicted translation: ['<start>']\n"
     ]
    }
   ],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "    sentence = inp_lang_tokenizer.encode(sentence)\n",
    "  \n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                            if i < tokenizer_en.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def translate(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "    predicted_sentence = ([targ_lang_tokenizer.index_word[i] for i in result.numpy()])  \n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)\n",
    "        \n",
    "translate(\"good morning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: how are you?\n",
      "Predicted translation: ['<start>', '?']\n"
     ]
    }
   ],
   "source": [
    "translate(\"how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
