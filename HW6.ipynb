{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Провести сравнение RNN, LSTM, GRU на датасете отзывов (из предыдущих занятий/материалов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import emoji\n",
    "from nltk import word_tokenize\n",
    "from string import punctuation, ascii_letters\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import regularizers\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 5000\n",
    "MAX_LEN = 20\n",
    "EMB_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(get_stop_words('ru'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation).union((' ', '«', '»', '—', '–', '“', '”', '…'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyrillic_letters = set([chr(i) for i in range(ord('а'), ord('я') + 1)] +\n",
    "                       [chr(i) for i in range(ord('А'), ord('Я') + 1)] +\n",
    "                       ['ё', 'Ё'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"отзывы за лето.xls\")\n",
    "data.columns = ['rating', 'content', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = (data.rating > 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        if (set(token).intersection(cyrillic_letters)\n",
    "            or set(token).intersection(set(ascii_letters))\n",
    "            or token in emoji.UNICODE_EMOJI):\n",
    "            result.append(token)\n",
    "    tokens = [token.lower() for token in result if token.lower() not in stop_words]\n",
    "    tokens = [token for token in tokens if token in emoji.UNICODE_EMOJI or len(token) >  1]\n",
    "    tokens = [morph.parse(token)[0].normal_form for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['processed'] = data.content.apply(lambda x: \" \".join(preprocess(str(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data['processed'], data['target'], test_size=0.2,\n",
    "                                                    random_state=42, stratify=data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_WORDS, oov_token='UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(tokenizer.texts_to_sequences(X_train),\n",
    "                        maxlen=MAX_LEN,\n",
    "                        padding='post',\n",
    "                        truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pad_sequences(tokenizer.texts_to_sequences(X_val),\n",
    "                        maxlen=MAX_LEN,\n",
    "                        padding='post',\n",
    "                        truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(vocab),\n",
    "                                       output_dim=EMB_SIZE,\n",
    "                                       activity_regularizer=regularizers.l2(1e-6))(inputs)\n",
    "rnn = tf.keras.layers.SimpleRNN(128, recurrent_dropout=0.2, activation='relu')(embeddings)\n",
    "dense = tf.keras.layers.Dense(64, activation='relu')(rnn)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16527 samples, validate on 4132 samples\n",
      "Epoch 1/10\n",
      "16527/16527 [==============================] - 6s 365us/sample - loss: 0.4576 - accuracy: 0.8014 - val_loss: 0.4074 - val_accuracy: 0.8427\n",
      "Epoch 2/10\n",
      "16527/16527 [==============================] - 2s 149us/sample - loss: 0.2876 - accuracy: 0.8736 - val_loss: 0.2543 - val_accuracy: 0.9025\n",
      "Epoch 3/10\n",
      "16527/16527 [==============================] - 2s 140us/sample - loss: 0.2452 - accuracy: 0.9055 - val_loss: 0.3381 - val_accuracy: 0.8974\n",
      "Epoch 4/10\n",
      "16527/16527 [==============================] - 2s 151us/sample - loss: 0.2222 - accuracy: 0.9163 - val_loss: 0.2868 - val_accuracy: 0.8998\n",
      "Epoch 5/10\n",
      "16527/16527 [==============================] - 2s 142us/sample - loss: 0.1980 - accuracy: 0.9265 - val_loss: 0.3148 - val_accuracy: 0.8969\n",
      "Epoch 6/10\n",
      "16527/16527 [==============================] - 2s 147us/sample - loss: 0.2005 - accuracy: 0.9150 - val_loss: 0.3403 - val_accuracy: 0.7713\n",
      "Epoch 7/10\n",
      "16527/16527 [==============================] - 2s 149us/sample - loss: 0.2362 - accuracy: 0.8735 - val_loss: 0.2916 - val_accuracy: 0.8843\n",
      "Epoch 8/10\n",
      "16527/16527 [==============================] - 2s 141us/sample - loss: 0.1844 - accuracy: 0.9292 - val_loss: 0.2672 - val_accuracy: 0.8887\n",
      "Epoch 9/10\n",
      "16527/16527 [==============================] - 2s 144us/sample - loss: 0.1697 - accuracy: 0.9315 - val_loss: 0.2917 - val_accuracy: 0.8981\n",
      "Epoch 10/10\n",
      "16527/16527 [==============================] - 2s 143us/sample - loss: 0.1698 - accuracy: 0.9285 - val_loss: 0.2712 - val_accuracy: 0.8884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c8aecd7908>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=256,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(vocab),\n",
    "                                       output_dim=EMB_SIZE,\n",
    "                                       activity_regularizer=regularizers.l2(1e-6))(inputs)\n",
    "lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(embeddings)\n",
    "dense = tf.keras.layers.Dense(64, activation='relu')(lstm)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16527 samples, validate on 4132 samples\n",
      "Epoch 1/10\n",
      "16527/16527 [==============================] - 8s 468us/sample - loss: 0.3769 - accuracy: 0.8434 - val_loss: 0.2301 - val_accuracy: 0.8988\n",
      "Epoch 2/10\n",
      "16527/16527 [==============================] - 5s 282us/sample - loss: 0.1981 - accuracy: 0.9160 - val_loss: 0.2061 - val_accuracy: 0.9126\n",
      "Epoch 3/10\n",
      "16527/16527 [==============================] - 4s 258us/sample - loss: 0.1650 - accuracy: 0.9352 - val_loss: 0.2082 - val_accuracy: 0.9131\n",
      "Epoch 4/10\n",
      "16527/16527 [==============================] - 4s 264us/sample - loss: 0.1461 - accuracy: 0.9451 - val_loss: 0.2265 - val_accuracy: 0.9102\n",
      "Epoch 5/10\n",
      "16527/16527 [==============================] - 4s 254us/sample - loss: 0.1295 - accuracy: 0.9523 - val_loss: 0.2398 - val_accuracy: 0.9083\n",
      "Epoch 6/10\n",
      "16527/16527 [==============================] - 4s 258us/sample - loss: 0.1176 - accuracy: 0.9578 - val_loss: 0.2935 - val_accuracy: 0.8986\n",
      "Epoch 7/10\n",
      "16527/16527 [==============================] - 4s 266us/sample - loss: 0.1057 - accuracy: 0.9607 - val_loss: 0.3031 - val_accuracy: 0.9008\n",
      "Epoch 8/10\n",
      "16527/16527 [==============================] - 4s 268us/sample - loss: 0.0937 - accuracy: 0.9651 - val_loss: 0.3124 - val_accuracy: 0.8984\n",
      "Epoch 9/10\n",
      "16527/16527 [==============================] - 4s 255us/sample - loss: 0.0829 - accuracy: 0.9692 - val_loss: 0.3277 - val_accuracy: 0.8959\n",
      "Epoch 10/10\n",
      "16527/16527 [==============================] - 4s 248us/sample - loss: 0.0772 - accuracy: 0.9720 - val_loss: 0.4235 - val_accuracy: 0.8942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c8abaf52c8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=256,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(vocab),\n",
    "                                       output_dim=EMB_SIZE,\n",
    "                                       activity_regularizer=regularizers.l2(1e-6))(inputs)\n",
    "gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64))(embeddings)\n",
    "dense = tf.keras.layers.Dense(64, activation='relu')(gru)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16527 samples, validate on 4132 samples\n",
      "Epoch 1/10\n",
      "16527/16527 [==============================] - 7s 426us/sample - loss: 0.3509 - accuracy: 0.8536 - val_loss: 0.2202 - val_accuracy: 0.9061\n",
      "Epoch 2/10\n",
      "16527/16527 [==============================] - 4s 270us/sample - loss: 0.1939 - accuracy: 0.9187 - val_loss: 0.2091 - val_accuracy: 0.9134\n",
      "Epoch 3/10\n",
      "16527/16527 [==============================] - 4s 239us/sample - loss: 0.1615 - accuracy: 0.9363 - val_loss: 0.2137 - val_accuracy: 0.9068\n",
      "Epoch 4/10\n",
      "16527/16527 [==============================] - 4s 253us/sample - loss: 0.1410 - accuracy: 0.9460 - val_loss: 0.2316 - val_accuracy: 0.9121\n",
      "Epoch 5/10\n",
      "16527/16527 [==============================] - 4s 251us/sample - loss: 0.1255 - accuracy: 0.9526 - val_loss: 0.2566 - val_accuracy: 0.9000\n",
      "Epoch 6/10\n",
      "16527/16527 [==============================] - 4s 264us/sample - loss: 0.1125 - accuracy: 0.9582 - val_loss: 0.2890 - val_accuracy: 0.8988\n",
      "Epoch 7/10\n",
      "16527/16527 [==============================] - 4s 252us/sample - loss: 0.0990 - accuracy: 0.9642 - val_loss: 0.2995 - val_accuracy: 0.8918\n",
      "Epoch 8/10\n",
      "16527/16527 [==============================] - 4s 259us/sample - loss: 0.0904 - accuracy: 0.9668 - val_loss: 0.3301 - val_accuracy: 0.8933\n",
      "Epoch 9/10\n",
      "16527/16527 [==============================] - 4s 235us/sample - loss: 0.0808 - accuracy: 0.9729 - val_loss: 0.3563 - val_accuracy: 0.8877\n",
      "Epoch 10/10\n",
      "16527/16527 [==============================] - 4s 237us/sample - loss: 0.0741 - accuracy: 0.9753 - val_loss: 0.3840 - val_accuracy: 0.8882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c8aed51308>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=256,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты у моделей похожи, немного лучше отработала GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
